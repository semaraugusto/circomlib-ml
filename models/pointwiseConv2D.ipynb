{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b70084b-44da-4142-9e24-c9c8231828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7533193-266d-4a59-b9aa-54179d40aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 21888242871839275222246405745257275088548364400416034343698204186575808495617\n",
    "\n",
    "class SeparableConv2D(nn.Module):\n",
    "    '''Separable convolution'''\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "        self.dw_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pw_conv =  nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dec98ed-cd14-442b-93b5-8f3660726773",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((1, 3, 5, 5))\n",
    "model = SeparableConv2D(3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92b62f7c-5ac1-4c69-9add-9a859d66c327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape=(6, 3, 1, 1)\n",
      "(5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "def PointwiseConv2dInt(nRows, nCols, nChannels, nFilters, strides, n, input, weights, bias):\n",
    "    kernelSize = 1\n",
    "    outRows = (nRows - kernelSize)//strides + 1\n",
    "    outCols = (nCols - kernelSize)//strides + 1\n",
    "    \n",
    "    Input = [[[str(input[i][j][k] % p) for k in range(nChannels)] for j in range(nCols)] for i in range(nRows)]\n",
    "    Weights = [[str(weights[k][l] % p) for l in range(nFilters)] for k in range(nChannels)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nFilters)]\n",
    "    out = [[[0 for _ in range(nFilters)] for _ in range(outCols)] for _ in range(outRows)]\n",
    "    str_out = [[[0 for _ in range(nFilters)] for _ in range(outCols)] for _ in range(outRows)]\n",
    "    remainder = [[[None for _ in range(nFilters)] for _ in range(outCols)] for _ in range(outRows)]\n",
    "    \n",
    "    for row in range(outRows):\n",
    "        for col in range(outCols):\n",
    "            for filter in range(nFilters):\n",
    "                for channel in range(nChannels):\n",
    "                    out[row][col][filter] += int(input[row*strides][col*strides][channel]) * int(weights[channel][filter])\n",
    "                            \n",
    "                out[row][col][filter] += int(bias[filter])\n",
    "                remainder[row][col][filter] = str(int(out[row][col][filter] % n))\n",
    "                out[row][col][filter] = str(out[row][col][filter] // n % p)\n",
    "    return Input, Weights, Bias, out, remainder\n",
    "    \n",
    "def PointwiseConv2d(nRows, nCols, nChannels, nFilters, strides, n, input, weights, bias):\n",
    "    kernelSize = 1\n",
    "    outRows = (nRows - kernelSize)//strides + 1\n",
    "    outCols = (nCols - kernelSize)//strides + 1\n",
    "    out = np.zeros((outRows, outCols, nFilters))\n",
    "    for row in range(outRows):\n",
    "        for col in range(outCols):\n",
    "            for filter in range(nFilters):\n",
    "                for k in range(nChannels):\n",
    "                    out[row, col, filter] += input[row*strides, col*strides, k] * weights[k, filter]\n",
    "                    \n",
    "                out[row][col][filter] += bias[filter]\n",
    "                out[row][col][filter] = out[row][col][filter] / n\n",
    "                            \n",
    "    return out\n",
    "\n",
    "EXPONENT = 8\n",
    "weights = model.pw_conv.weight.detach().numpy()\n",
    "print(f\"{weights.shape=}\")\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "\n",
    "expected = model.pw_conv(input).detach().numpy()\n",
    "\n",
    "padded = input.squeeze().numpy().transpose((1, 2, 0))\n",
    "print(padded.shape)\n",
    "weights = weights.transpose((2, 3, 1, 0)).squeeze()\n",
    "\n",
    "actual = PointwiseConv2d(5, 5, 3, 6, 1, 1, padded, weights, bias)\n",
    "\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c664ba3-b722-482b-84f4-f83bab1d1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized_image.shape=(5, 5, 3)\n",
      "quantized_weights.shape=(3, 6)\n",
      "actual.shape=(5, 5, 6)\n",
      "expected.shape=(1, 6, 5, 5)\n",
      "expected.shape=(5, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "EXPONENT = 15\n",
    "\n",
    "weights = model.pw_conv.weight.detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "\n",
    "expected = model.pw_conv(input).detach().numpy()\n",
    "\n",
    "weights = weights.transpose((2, 3, 1, 0)).squeeze()\n",
    "\n",
    "quantized_image = input.squeeze().numpy().transpose((1, 2, 0)) * 10**EXPONENT\n",
    "quantized_weights = weights * 10**EXPONENT\n",
    "print(f\"{quantized_image.shape=}\")\n",
    "print(f\"{quantized_weights.shape=}\")\n",
    "\n",
    "actual = PointwiseConv2d(5, 5, 3, 6, 1, 10**EXPONENT, quantized_image.round(), quantized_weights.round(), bias)\n",
    "\n",
    "actual = actual / 10**(EXPONENT)\n",
    "print(f\"{actual.shape=}\")\n",
    "print(f\"{expected.shape=}\")\n",
    "\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "print(f\"{expected.shape=}\")\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b595d39-ca92-4c45-b04e-e7eb85b4c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_input, q_weights, str_bias, str_actual, rem  = PointwiseConv2dInt(5, 5, 3, 3, 1, 10**EXPONENT, quantized_image.round().astype(int), quantized_weights.round().astype(int), bias.astype(int))\n",
    "\n",
    "input_json_path = \"pointwiseConv2D_input.json\"\n",
    "with open(input_json_path, \"w\") as input_file:\n",
    "    json.dump({\"in\": q_input,\n",
    "               \"weights\": q_weights,\n",
    "               \"remainder\": rem,\n",
    "               \"out\": str_actual,\n",
    "               \"bias\": str_bias,\n",
    "              },\n",
    "              input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7213b-a2cb-4085-bb87-64997eb97253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
