{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d60427f-21e9-41b1-a5eb-0d36d2c395ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1962e3f-18b6-43b2-88f8-e81a49f4edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2D(nn.Module):\n",
    "    '''Separable convolution'''\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "        self.dw_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "        )\n",
    "        self.pw_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x\n",
    "\n",
    "CIRCOM_PRIME = 21888242871839275222246405745257275088548364400416034343698204186575808495617\n",
    "MAX_POSITIVE = CIRCOM_PRIME // 2\n",
    "MAX_NEGATIVE = MAX_POSITIVE + 1 # The most positive number\n",
    "CIRCOM_NEGATIVE_1 = 21888242871839275222246405745257275088548364400416034343698204186575808495617 - 1\n",
    "\n",
    "def from_circom(x):\n",
    "    if type(x) != int:\n",
    "        x = int(x)\n",
    "    if x > MAX_POSITIVE: \n",
    "        return x - CIRCOM_PRIME\n",
    "    return x\n",
    "    \n",
    "def to_circom(x):\n",
    "    if type(x) != int:\n",
    "        x = int(x)\n",
    "    if x < 0:\n",
    "        return x + CIRCOM_PRIME \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7ad1f77-24e0-470e-b4de-63234ac9542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((1, 3, 5, 5))\n",
    "\n",
    "model = SeparableConv2D(3, 3)\n",
    "expected = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88e91743-d234-4e55-bd65-f4a5b0f5b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DInt(nRows, nCols, nChannels, nFilters, kernelSize, strides, n, input, weights, bias):\n",
    "    Input = [[[str(input[i][j][k] % p) for k in range(nChannels)] for j in range(nCols)] for i in range(nRows)]\n",
    "    Weights = [[[[str(weights[i][j][k][l] % p) for l in range(nFilters)] for k in range(nChannels)] for j in range(kernelSize)] for i in range(kernelSize)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nFilters)]\n",
    "    out = [[[0 for _ in range(nFilters)] for _ in range((nCols - kernelSize)//strides + 1)] for _ in range((nRows - kernelSize)//strides + 1)]\n",
    "    remainder = [[[None for _ in range(nFilters)] for _ in range((nCols - kernelSize)//strides + 1)] for _ in range((nRows - kernelSize)//strides + 1)]\n",
    "    for i in range((nRows - kernelSize)//strides + 1):\n",
    "        for j in range((nCols - kernelSize)//strides + 1):\n",
    "            for m in range(nFilters):\n",
    "                for k in range(nChannels):\n",
    "                    for x in range(kernelSize):\n",
    "                        for y in range(kernelSize):\n",
    "                            out[i][j][m] += input[i*strides+x][j*strides+y][k] * weights[x][y][k][m]\n",
    "                out[i][j][m] += bias[m]\n",
    "                remainder[i][j][m] = str(out[i][j][m] % n)\n",
    "                out[i][j][m] = str(out[i][j][m] // n % p)\n",
    "    return Input, Weights, Bias, out, remainder\n",
    "    \n",
    "def DepthwiseConv(nRows, nCols, nChannels, nFilters, kernelSize, strides, n, input, weights, bias):\n",
    "    assert(nFilters % nChannels == 0)\n",
    "    outRows = (nRows - kernelSize)//strides + 1\n",
    "    outCols = (nCols - kernelSize)//strides + 1\n",
    "    out = np.zeros((outRows, outCols, nFilters))\n",
    "    remainder = np.zeros((outRows, outCols, nFilters))\n",
    "    \n",
    "    for row in range(outRows):\n",
    "        for col in range(outCols):\n",
    "            for channel in range(nChannels):\n",
    "                for x in range(kernelSize):\n",
    "                    for y in range(kernelSize):\n",
    "                        out[row, col, channel] += input[row*strides+x, col*strides+y, channel] * weights[x, y, channel]\n",
    "            # remainder[i][j][m] = str(out[i][j][m] % n)\n",
    "                \n",
    "                out[row][col][channel] += bias[channel]\n",
    "                remainder[row][col][channel] = out[row][col][channel] % n\n",
    "                out[row][col][channel] = out[row][col][channel] / n\n",
    "                            \n",
    "    return out, remainder\n",
    "\n",
    "weights = model.dw_conv[0].weight.squeeze().detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "# input = torch.randn((1, 8, 32, 32))\n",
    "\n",
    "expected = model.dw_conv[0](input).detach().numpy()\n",
    "\n",
    "# # Converting to H x W x C\n",
    "padded = F.pad(input, (1,1,1,1), \"constant\", 0) # Padding for convolution with \"same\" configuration\n",
    "padded = padded.squeeze().numpy().transpose((1, 2, 0))\n",
    "weights = weights.transpose((1, 2, 0))\n",
    "\n",
    "actual, rem = DepthwiseConv(7, 7, 3, 3, 3, 1, 1, padded, weights, bias)\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e666c225-f618-43d4-b003-56f9b4699d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPONENT = 8\n",
    "weights = model.dw_conv[0].weight.squeeze().detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "# input = torch.randn((1, 8, 32, 32))\n",
    "\n",
    "expected = model.dw_conv[0](input).detach().numpy()\n",
    "\n",
    "# # Converting to H x W x C\n",
    "padded = F.pad(input, (1,1,1,1), \"constant\", 0)\n",
    "padded = padded.squeeze().numpy().transpose((1, 2, 0))\n",
    "weights = weights.transpose((1, 2, 0))\n",
    "\n",
    "quantized_image = padded * 10**EXPONENT\n",
    "quantized_weights = weights * 10**EXPONENT\n",
    "\n",
    "actual, _ = DepthwiseConv(7, 7, 3, 3, 3, 1, 10**EXPONENT, quantized_image, quantized_weights, bias)\n",
    "actual = actual / 10**(EXPONENT)\n",
    "\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49b25dcb-3c1c-4dec-a2ad-528b61d5749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 3)\n",
      "(7, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "print(quantized_image.shape)\n",
    "input_json_path = \"depthwiseConv2D_input.json\"\n",
    "print(quantized_image.shape)\n",
    "with open(input_json_path, \"w\") as input_file:\n",
    "    json.dump({\"in\": quantized_image.round().astype(int).tolist(),\n",
    "               \"weights\": quantized_weights.round().tolist(),\n",
    "               \"bias\": bias.astype(int).tolist(),\n",
    "              },\n",
    "              input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89060d-c9ae-410b-8f87-8f78c5ee912f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
