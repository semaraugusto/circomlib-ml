{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d60427f-21e9-41b1-a5eb-0d36d2c395ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b1962e3f-18b6-43b2-88f8-e81a49f4edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2D(nn.Module):\n",
    "    '''Separable convolution'''\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "        self.dw_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "        )\n",
    "        self.pw_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a7ad1f77-24e0-470e-b4de-63234ac9542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((1, 3, 5, 5))\n",
    "model = SeparableConv2D(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "88e91743-d234-4e55-bd65-f4a5b0f5b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DepthwiseConvInt(nRows, nCols, nChannels, nFilters, kernelSize, strides, n, input, weights, bias):\n",
    "    assert(nFilters % nChannels == 0)\n",
    "    outRows = (nRows - kernelSize)//strides + 1\n",
    "    outCols = (nCols - kernelSize)//strides + 1\n",
    "    \n",
    "    Input = [[[str(input[i][j][k] % p) for k in range(nChannels)] for j in range(nCols)] for i in range(nRows)]\n",
    "    Weights = [[[str(weights[i][j][k] % p) for k in range(nChannels)] for j in range(kernelSize)] for i in range(kernelSize)]\n",
    "    Bias = [str(bias[i] % p) for i in range(nFilters)]\n",
    "    out = [[[0 for _ in range(nFilters)] for _ in range(outCols)] for _ in range(outRows)]\n",
    "    remainder = [[[None for _ in range(nFilters)] for _ in range(outCols)] for _ in range(outRows)]\n",
    "    \n",
    "    for row in range(outRows):\n",
    "        for col in range(outCols):\n",
    "            for channel in range(nChannels):\n",
    "                for x in range(kernelSize):\n",
    "                    for y in range(kernelSize):\n",
    "                        out[row][col][channel] += input[row*strides+x][col*strides+y][channel] * weights[x][y][channel]\n",
    "                        \n",
    "                out[row][col][channel] += bias[channel]\n",
    "                remainder[row][col][channel] = str(out[row][col][channel] % n)\n",
    "                out[row][col][channel] = str((out[row][col][channel] // n) % p)\n",
    "                \n",
    "    return Input, Weights, Bias, out, remainder\n",
    "    \n",
    "def DepthwiseConv(nRows, nCols, nChannels, nFilters, kernelSize, strides, n, input, weights, bias):\n",
    "    assert(nFilters % nChannels == 0)\n",
    "    outRows = (nRows - kernelSize)//strides + 1\n",
    "    outCols = (nCols - kernelSize)//strides + 1\n",
    "    \n",
    "    out = np.zeros((outRows, outCols, nFilters))\n",
    "    remainder = np.zeros((outRows, outCols, nFilters))\n",
    "    \n",
    "    for row in range(outRows):\n",
    "        for col in range(outCols):\n",
    "            for channel in range(nChannels):\n",
    "                for x in range(kernelSize):\n",
    "                    for y in range(kernelSize):\n",
    "                        out[row, col, channel] += input[row*strides+x, col*strides+y, channel] * weights[x, y, channel]\n",
    "                \n",
    "                out[row][col][channel] += bias[channel]\n",
    "                remainder[row][col][channel] = out[row][col][channel] % n\n",
    "                out[row][col][channel] = out[row][col][channel] / n\n",
    "                            \n",
    "    return out, remainder\n",
    "\n",
    "weights = model.dw_conv[0].weight.squeeze().detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "# input = torch.randn((1, 8, 32, 32))\n",
    "\n",
    "expected = model.dw_conv[0](input).detach().numpy()\n",
    "\n",
    "# # Converting to H x W x C\n",
    "padded = F.pad(input, (1,1,1,1), \"constant\", 0) # Padding for convolution with \"same\" configuration\n",
    "padded = padded.squeeze().numpy().transpose((1, 2, 0))\n",
    "weights = weights.transpose((1, 2, 0))\n",
    "\n",
    "actual, rem = DepthwiseConv(7, 7, 3, 3, 3, 1, 1, padded, weights, bias)\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e666c225-f618-43d4-b003-56f9b4699d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXPONENT = 8\n",
    "    \n",
    "weights = model.dw_conv[0].weight.squeeze().detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "# input = torch.randn((1, 8, 32, 32))\n",
    "\n",
    "expected = model.dw_conv[0](input).detach().numpy()\n",
    "\n",
    "# # Converting to H x W x C\n",
    "padded = F.pad(input, (1,1,1,1), \"constant\", 0)\n",
    "padded = padded.squeeze().numpy().transpose((1, 2, 0))\n",
    "weights = weights.transpose((1, 2, 0))\n",
    "\n",
    "quantized_image = padded * 10**EXPONENT\n",
    "quantized_weights = weights * 10**EXPONENT\n",
    "\n",
    "actual, rem = DepthwiseConv(7, 7, 3, 3, 3, 1, 10**EXPONENT, quantized_image.round(), quantized_weights.round(), bias)\n",
    "actual = actual / 10**(EXPONENT)\n",
    "\n",
    "expected = expected.squeeze().transpose((1, 2, 0))\n",
    "\n",
    "assert(np.allclose(expected, actual, atol=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "904ce6c4-f1d4-43f3-80f0-5e3df61d5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.dw_conv[0].weight.squeeze().detach().numpy()\n",
    "bias = torch.zeros(weights.shape[0]).numpy()\n",
    "\n",
    "padded = F.pad(input, (1,1,1,1), \"constant\", 0)\n",
    "padded = padded.squeeze().numpy().transpose((1, 2, 0))\n",
    "weights = weights.transpose((1, 2, 0))\n",
    "\n",
    "quantized_image = padded * 10**EXPONENT\n",
    "quantized_weights = weights * 10**EXPONENT\n",
    "\n",
    "q_input, q_weights, bias, actual, rem = DepthwiseConvInt(7, 7, 3, 3, 3, 1, 10**EXPONENT, quantized_image.round().astype(int), quantized_weights.round().astype(int), bias.astype(int))\n",
    "\n",
    "input_json_path = \"depthwiseConv2D_input.json\"\n",
    "with open(input_json_path, \"w\") as input_file:\n",
    "    json.dump({\"in\": q_input,\n",
    "               \"weights\": q_weights,\n",
    "               \"remainder\": rem,\n",
    "               \"out\": actual,\n",
    "               \"bias\": bias,\n",
    "              },\n",
    "              input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
